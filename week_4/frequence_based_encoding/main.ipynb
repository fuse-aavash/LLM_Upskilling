{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591b6ae7-1b61-4400-a09b-28943e22b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_corpus = [\"these are beautiful flowers flowers\",\n",
    "                   \"those are ugly cars cars\",\n",
    "                    \"it is a fast car car\",\n",
    "                    \"she has a cute dog dog\",\n",
    "                    \"this pizza is delicious delicious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade04659-59ac-40e5-936d-eb622bcd3b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'are', 'beautiful', 'car', 'cars', 'cute', 'delicious', 'dog', 'fast', 'flowers', 'has', 'is', 'it', 'pizza', 'she', 'these', 'this', 'those', 'ugly']\n"
     ]
    }
   ],
   "source": [
    "data_corpus = set()\n",
    "for row in document_corpus:\n",
    "    for word in row.split(\" \"):\n",
    "        if word not in data_corpus:\n",
    "            data_corpus.add(word)\n",
    "\n",
    "data_corpus=sorted(data_corpus)\n",
    "\n",
    "print(data_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db27b0be-2407-4cd6-814a-cd3e915ac2cc",
   "metadata": {},
   "source": [
    "## Index Based Encoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3d09ba-4ed2-4424-ace6-f62ee1112bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "res = len(max(document_corpus, key = len).split(\" \"))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03ce928-b81f-4add-b128-a9b6c8fbec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 2, 3, 10, 10], [18, 2, 19, 5, 5], [13, 12, 1, 9, 4], [15, 11, 1, 6, 8], [17, 14, 12, 7, 7]]\n"
     ]
    }
   ],
   "source": [
    "index_based_encoding=[]\n",
    "for row in document_corpus:\n",
    "    row_encoding = []\n",
    "    split = row.split(\" \")\n",
    "    for i in range(res):\n",
    "        if i <= len(split)-1:\n",
    "            row_encoding.append(data_corpus.index(split[i])+1)\n",
    "        else:\n",
    "            row_encoding.append(0)\n",
    "    index_based_encoding.append(row_encoding)\n",
    "\n",
    "print(index_based_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c097e9d-3b7e-4cf9-aa58-e27e306452a7",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "### 1. Binary BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d94882b-3d79-4e3c-be9a-64e1f0e5422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoding = []\n",
    "for row in document_corpus:\n",
    "    row_encoding = []\n",
    "    split = row.split(\" \")\n",
    "    for word in data_corpus:\n",
    "        if word in split:\n",
    "            row_encoding.append(1)\n",
    "        else:\n",
    "            row_encoding.append(0)\n",
    "    one_hot_encoding.append(row_encoding)\n",
    "\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f930899-946b-485c-83bb-1cc92aa2109c",
   "metadata": {},
   "source": [
    "### 2. BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd66732f-e5ed-444c-a658-caca74d9bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoding = []\n",
    "for row in document_corpus:\n",
    "    row_encoding = []\n",
    "    split = row.split(\" \")\n",
    "    for word in data_corpus:\n",
    "        count = split.count(word)\n",
    "        if word in split:\n",
    "            row_encoding.append(count)\n",
    "        else:\n",
    "            row_encoding.append(count)\n",
    "    one_hot_encoding.append(row_encoding)\n",
    "\n",
    "print(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d623a8-3c4b-4b78-84bb-571541499a79",
   "metadata": {},
   "source": [
    "## TF-IDF Encoding :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f80cb84-b38c-4a25-938c-4d0884d19a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'these': 1, 'are': 1, 'beautiful': 1, 'flowers': 2}, 1: {'those': 1, 'are': 1, 'ugly': 1, 'cars': 2}, 2: {'it': 1, 'is': 1, 'a': 1, 'fast': 1, 'car': 2}, 3: {'she': 1, 'has': 1, 'a': 1, 'cute': 1, 'dog': 2}, 4: {'this': 1, 'pizza': 1, 'is': 1, 'delicious': 2}}\n"
     ]
    }
   ],
   "source": [
    "tf_dict = {}\n",
    "i=0\n",
    "for row in document_corpus:\n",
    "    row_dict={}\n",
    "    split = row.split(\" \")\n",
    "    for word in split:\n",
    "        if word not in row_dict.keys():\n",
    "            row_dict[word] = split.count(word)\n",
    "    tf_dict[i] = row_dict\n",
    "    i+=1\n",
    "\n",
    "print(tf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a729280c-3cd2-4d92-8df6-a382d00bc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_tf(word, sentence_num):\n",
    "    row_dict = tf_dict[int(sentence_num)]\n",
    "    return row_dict[word]/sum(row_dict.values())\n",
    "\n",
    "def calculate_idf(word):\n",
    "    doc_num = 0\n",
    "    for key, value in tf_dict.items():\n",
    "        if word in value.keys():\n",
    "            doc_num+=1\n",
    "    return math.log(len(data_corpus)/doc_num+1)\n",
    "\n",
    "def tf_idf(word, sentence_num):\n",
    "    return round(calculate_tf(word, sentence_num) * calculate_idf(word),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a5bf81-d694-4d8a-a9b0-aebcdb0d7905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.19829"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf('flowers',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256d5941-d355-4d34-a46c-2478138fa69c",
   "metadata": {},
   "source": [
    "## Scikit-Learn Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f244091-0c47-4776-a634-ef2b97036190",
   "metadata": {},
   "source": [
    "### BoW Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e103779-9664-4b49-a25c-e10cdb73051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['are' 'beautiful' 'car' 'cars' 'cute' 'delicious' 'dog' 'fast' 'flowers'\n",
      " 'has' 'is' 'it' 'pizza' 'she' 'these' 'this' 'those' 'ugly']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(document_corpus)\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b014c-1137-4230-be59-da0f97859158",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
